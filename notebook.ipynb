{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.52s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pyplot\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.transforms import Resize\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import torch\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "coco = COCO('data/annotations/instances_val2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['potted plant', 'tv', 'tv', 'chair', 'chair', 'chair', 'chair', 'person', 'person', 'microwave', 'refrigerator', 'book', 'book', 'clock', 'vase', 'vase', 'chair', 'vase', 'vase', 'dining table']\n"
     ]
    }
   ],
   "source": [
    "img = coco.loadImgs(139)\n",
    "annIds = coco.getAnnIds(139)\n",
    "anns = coco.loadAnns(annIds)\n",
    "cat_ids = [ann['category_id'] for ann in anns]\n",
    "# cats = [cat['name'] for cat in cat_ids]\n",
    "cat_objs = coco.loadCats(cat_ids)\n",
    "cats = [cat_obj['name'] for cat_obj in cat_objs]\n",
    "print(cats)\n",
    "mask = np.zeros((img[0]['height'], img[0]['width']))\n",
    "for ann in anns:\n",
    "    mask = np.maximum(coco.annToMask(ann) * ann['category_id'], mask)\n",
    "\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = './data'\n",
    "dataType = 'val2017'\n",
    "\n",
    "# Define the classes (out of the 81) which you want to see. Others will not be shown.\n",
    "filterClasses = ['laptop']\n",
    "\n",
    "# Fetch class IDs only corresponding to the filterClasses\n",
    "catIds = coco.getCatIds(catNms=filterClasses) \n",
    "# Get all images containing the above Category IDs\n",
    "imgIds = coco.getImgIds(catIds=catIds)\n",
    "print(\"Number of images containing all the  classes:\", len(imgIds))\n",
    "\n",
    "img = coco.loadImgs(imgIds[0])[0]\n",
    "I2 = io.imread('{}/images/{}/{}'.format(dataDir,dataType,img['file_name']))/255.0\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(I2)\n",
    "plt.show()\n",
    "annIds = coco.getAnnIds(imgIds=img['id'], catIds=catIds, iscrowd=None)\n",
    "anns = coco.loadAnns(annIds)\n",
    "coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = coco.loadImgs(724)\n",
    "ann_id = coco.getAnnIds(imgIds=[724], iscrowd=None)\n",
    "anns = coco.loadAnns(ann_id)\n",
    "coco.showAnns(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path_list = glob.glob('data/images/val2017/*')\n",
    "val_path_list.sort()\n",
    "trn_path_list = glob.glob('data/images/train2017/*')\n",
    "trn_path_list.sort()\n",
    "\n",
    "trn_img_ids = [int(os.path.split(path)[-1][:12]) for path in trn_path_list]\n",
    "trn_ann_ids = [coco.getAnnIds(img_id) for img_id in trn_img_ids]\n",
    "val_img_ids = [int(os.path.split(path)[-1][:12]) for path in val_path_list]\n",
    "val_ann_ids = [coco.getAnnIds(img_id) for img_id in val_img_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000000139\n",
      "000000000285\n",
      "000000000632\n",
      "000000000724\n",
      "000000000776\n",
      "000000000785\n",
      "000000000802\n",
      "000000000872\n",
      "000000000885\n",
      "000000001000\n"
     ]
    }
   ],
   "source": [
    "for path in val_path_list[:10]:\n",
    "    img_id = os.path.split(path)[-1][:12]\n",
    "    print(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "[48114932.34509832 45697304.97647042 41642151.05098017] [66724295.21849895 64859325.40604324 60868457.99031425]\n"
     ]
    }
   ],
   "source": [
    "t_psum = np.array([0.0, 0.0, 0.0], dtype=np.double)\n",
    "t_psum_sq = np.array([0.0, 0.0, 0.0], dtype=np.double)\n",
    "resize = Resize((64, 64))\n",
    "\n",
    "for i, name in enumerate(trn_path_list):\n",
    "    image = Image.open(name)\n",
    "    image = resize(image)\n",
    "    np_data = np.asarray(image)\n",
    "    np_data = np_data / 255\n",
    "    # print(np_data.shape)\n",
    "    if len(np_data.shape) == 3:\n",
    "        t_psum += np.sum(np_data, axis=(0, 1))\n",
    "        t_psum_sq += np.sum(np.sqrt(np_data), axis=(0, 1))\n",
    "    else:\n",
    "        t_psum += np.sum(np_data)\n",
    "        t_psum_sq += np.sum(np.sqrt(np_data))\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "print(t_psum, t_psum_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46987239 0.44626274 0.40666163] [0.43082439 0.43424141 0.42904485]\n"
     ]
    }
   ],
   "source": [
    "count = 25000 * 64 * 64\n",
    "t_mean = t_psum / count\n",
    "t_std = t_psum_sq/count - t_mean**2\n",
    "print(t_mean, t_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "[9614006.80392156 9134584.07450981 8327300.03529412] [13334281.85762674 12969273.83953184 12179058.96998939]\n"
     ]
    }
   ],
   "source": [
    "v_psum = np.array([0.0, 0.0, 0.0], dtype=np.double)\n",
    "v_psum_sq = np.array([0.0, 0.0, 0.0], dtype=np.double)\n",
    "resize = Resize((64, 64))\n",
    "\n",
    "for i, name in enumerate(val_path_list):\n",
    "    image = Image.open(name)\n",
    "    image = resize(image)\n",
    "    np_data = np.asarray(image)\n",
    "    np_data = np_data / 255\n",
    "    if len(np_data.shape) == 3:\n",
    "        v_psum += np.sum(np_data, axis=(0, 1))\n",
    "        v_psum_sq += np.sum(np.sqrt(np_data), axis=(0, 1))\n",
    "    else:\n",
    "        v_psum += np.sum(np_data)\n",
    "        v_psum_sq += np.sum(np.sqrt(np_data))\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "print(v_psum, v_psum_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46943393 0.44602461 0.40660645] [0.43071977 0.43432737 0.42935181]\n"
     ]
    }
   ],
   "source": [
    "count = 5000 * 64 * 64\n",
    "v_mean = v_psum / count\n",
    "v_std = v_psum_sq/count - v_mean**2\n",
    "print(v_mean, v_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "torch.Size([426, 640])\n",
      "(426, 640)\n"
     ]
    }
   ],
   "source": [
    "resize = Resize((64, 64))\n",
    "for i, path in enumerate(val_path_list):\n",
    "    image = Image.open(path)\n",
    "    image = resize(image)\n",
    "    np_data = np.asarray(image)\n",
    "    if len(np_data.shape) == 2:\n",
    "        np_data = np.stack([np_data, np_data, np_data], axis=2)\n",
    "    np_data = np.divide(np_data-t_mean, t_std)\n",
    "    print(np_data.shape)\n",
    "\n",
    "    img_id = val_img_ids[i]\n",
    "    img = coco.loadImgs(img_id)\n",
    "    ann_ids = coco.getAnnIds(img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    mask = np.zeros((img[0]['height'], img[0]['width']))\n",
    "    for ann in anns:\n",
    "        mask = np.maximum(coco.annToMask(ann) * ann['category_id'], mask)\n",
    "    mask_tensor = torch.from_numpy(mask)\n",
    "    print(mask_tensor.size())\n",
    "    mask_resized = resize(mask_tensor.unsqueeze(0)).squeeze()\n",
    "    mask = np.asarray(mask_tensor).astype(int)\n",
    "    print(mask.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_w = 0\n",
    "max_h = 0\n",
    "min_w = 1000\n",
    "min_h = 1000\n",
    "min_ratio = 10\n",
    "max_ratio = 0\n",
    "\n",
    "for i, name in enumerate(val_path_list):\n",
    "    image = Image.open(name)\n",
    "    np_data = np.asarray(image)\n",
    "    h, w = np_data.shape[:2]\n",
    "    min_w = min(min_w, w)\n",
    "    min_h = min(min_h, h)\n",
    "    max_w = max(max_w, w)\n",
    "    max_h = max(max_h, h)\n",
    "\n",
    "    ratio_1 = h / w\n",
    "    ratio_2 = w / h\n",
    "    min_ratio = min(min_ratio, ratio_1, ratio_2)\n",
    "    max_ratio = max(min_ratio, ratio_1, ratio_2)\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "print('max_w:', max_w)\n",
    "print('max_h:', max_h)\n",
    "print('min_w:', min_w)\n",
    "print('min_h:', min_h)\n",
    "print('min_ratio:', min_ratio)\n",
    "print('max_ratio:', max_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_max_w = 0\n",
    "t_max_h = 0\n",
    "t_min_w = 1000\n",
    "t_min_h = 1000\n",
    "t_min_ratio = 10\n",
    "t_max_ratio = 0\n",
    "\n",
    "for i, name in enumerate(trn_path_list):\n",
    "    image = Image.open(name)\n",
    "    np_data = np.asarray(image)\n",
    "    h, w = np_data.shape[:2]\n",
    "    t_min_w = min(t_min_w, w)\n",
    "    t_min_h = min(t_min_h, h)\n",
    "    t_max_w = max(t_max_w, w)\n",
    "    t_max_h = max(t_max_h, h)\n",
    "\n",
    "    ratio_1 = h / w\n",
    "    ratio_2 = w / h\n",
    "    t_min_ratio = min(t_min_ratio, ratio_1, ratio_2)\n",
    "    t_max_ratio = max(t_min_ratio, ratio_1, ratio_2)\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "\n",
    "print('t_max_w:', t_max_w)\n",
    "print('t_max_h:', t_max_h)\n",
    "print('t_min_w:', t_min_w)\n",
    "print('t_min_h:', t_min_h)\n",
    "print('t_min_ratio:', t_min_ratio)\n",
    "print('t_max_ratio:', t_max_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 640, 3)\n",
      "JPEG\n",
      "(640, 426)\n",
      "RGB\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('data/images/val2017/000000000139.jpg')\n",
    "np_data = np.asarray(image)\n",
    "print(np_data.shape)\n",
    "print(image.format)\n",
    "print(image.size)\n",
    "print(image.mode)\n",
    "pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c635020d71857411e75f216e7c5ce1f8b739730c5d2238d089ea40f991b51d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
